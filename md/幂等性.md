### 简述

幂等性，简单来说就是多次调用系统产生的影响与调用一次系统是一样的，即对资源的作用时一样的

以SQL为例，有些操作时天然幂等的。

```sql
select * from table where id = ?
update table set col1 = 1 where col2 = 2
delete from user where user_id = 1
insert into user (user_id,name) values(1,'a')
#当insert的user_id为唯一主键，多次执行插入操作只会新增一条记录，具备幂等性。
```

### 幂等解决方案

1. #### token 机制

> 服务端提供了发送 token 的接口。我们在分析业务的时候，哪些业务是存在幂等问题的，就必须在执行业务前，先去获取 token，服务器会把 token 保存到 redis 中。
>
> **前端调用业务接口请求时，把 token 携带过去，一般放在请求头部。**
>
> 服务器判断 token 是否存在 redis 中，存在表示第一次请求，然后删除 token，继续执行业务。
>
> 如果判断 token 不存在 redis 中，就表示是重复操作，直接返回重复标记给 client，这样就保证了业务代码，不被重复执行。
>

##### 	危险性：

###### <font color='red'> 先删除 token 还是后删除 token ？</font>

> A、先删除可能导致，业务确实没有执行，重试还带上之前 token，由于防重设计导致，请求还是不能执行。
>
> B、后删除可能导致，业务处理成功，但是服务闪断，出现超时，没有删除 token，别人继续重试，导致业务被执行两次。
>
> C、我们最好设计为先删除 token，如果业务调用失败，就重新获取 token 再次请求。
>

###### <font color='red'> Token 获取、比较和删除必须是原子性 ？</font>

A、```redis.get(token) ```、```token.equals```、```redis.del(token)``` 如果这两个操作不是原子，可能导致，高并发下，都 get 到同样的数据，判断都成功，继续业务并发执行

B、可以在 redis 使用 lua 脚本完成这个操作

##### 可以使用*redisTemplate.execute()*方法执行lua脚本，第二个参数等于KEYS[1]，第三个参数等于ARGV[1]

```java
String script = "if redis.call('get', KEYS[1]) == ARGV[1] then return redis.call('del', KEYS[1]) else return 0 end";
Long result = (long) redisTemplate.execute(new DefaultRedisScript<>(script, Long.class),
        Arrays.asList("testKey"),
        "testValue");
```



#### 2. 各种锁机制

###### 数据库悲观锁

```sql
select * from xxxx where id = 1 for update;
```

悲观锁使用时一般伴随事务一起使用，数据锁定时间可能会很长，需要根据实际情况选用。另外要注意的是，id 字段一定是主键或者唯一索引，不然可能造成锁表的结果，处理起来会非常麻烦。

###### **数据库乐观锁**

这种方法适合在更新的场景中,乐观锁主要使用于处理读多写少的问题。

```sql
update t_goods set count = count -1 , version = version + 1 where good_id=2 and version = 1
```



#### 3. 各种唯一约束

###### A、数据库唯一约束

插入数据，应该按照唯一索引进行插入，比如订单号，相同的订单就不可能有两条记录插入。我们在数据库层面防止重复。

这个机制是利用了数据库的主键唯一约束的特性，解决了在 insert 场景时幂等问题。但主键的要求不是自增的主键，这样就需要业务生成全局唯一的主键。

如果是分库分表场景下，路由规则要保证相同请求下，落地在同一个数据库和同一表中，要不然数据库主键约束就不起效果了，因为是不同的数据库和表主键不相关。

###### B、redis set 防重

很多数据需要处理，只能被处理一次，比如我们可以计算数据的 MD5 将其放入redis 的set，每次处理数据，先看这个 MD5 是否已经存在，存在就不处理。

###### C、防重表

使用订单号 orderNo 做为去重表的唯一索引，把唯一索引插入去重表，再进行业务操作，且他们在同一个事务中。这个保证了重复请求时，因为去重表有唯一约束，导致请求失败，避免了幂等问题。这里要注意的是，去重表和业务表应该在同一库中，这样就保证了在同一个事务，即使业务操作失败了，也会把去重表的数据回滚。这个很好的保证了数据一致性。之前说的 redis 防重也算

###### D、全局请求唯一 id

调用接口时，生成一个唯一 id，redis 将数据保存到集合中 (去重) ，存在即处理过。可以使用 nginx 设置每一个请求的唯一 id；

```nginx
proxy_set_header X-Request-Id $request_id;
```

